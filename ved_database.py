import json
import os
from pathlib import Path
from typing import Dict, List, Optional
import logging

logger = logging.getLogger("VED_DATABASE")

class VEDDatabase:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –¢–ù –í–≠–î"""

    def __init__(self, data_path=None):
        if data_path is None:
            data_path = Path(__file__).parent
        else:
            data_path = Path(data_path)

        self.data_path = data_path
        self.database = {}
        self.codes_index = {}  # –ò–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É
        self.name_index = {}   # –ò–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        self._cache = {}       # –ö—ç—à –¥–ª—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self._load_database()

    def _load_database(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π"""
        try:
            db_file = self.data_path / "tnved_database.json"
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∏–∑: {db_file}")

            with open(db_file, "r", encoding="utf-8") as f:
                self.database = json.load(f)

            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            self._build_indexes()

            codes_count = len(self.database.get("codes", []))
            logger.info(f"‚úÖ VEDDatabase –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {codes_count} –∫–æ–¥–æ–≤")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {e}")
            self.database = {"codes": [], "groups": []}

    def _build_indexes(self):
        """–°—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞"""
        codes = self.database.get("codes", [])

        for code_data in codes:
            code = code_data.get("code", "")
            name = code_data.get("name", "").lower()

            # –ò–Ω–¥–µ–∫—Å –ø–æ –∫–æ–¥—É
            self.codes_index[code] = code_data

            # –ò–Ω–¥–µ–∫—Å –ø–æ —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
            words = name.split()
            for word in words:
                if len(word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                    if word not in self.name_index:
                        self.name_index[word] = []
                    self.name_index[word].append(code_data)

    def find_by_code(self, code: str) -> Optional[Dict]:
        """–ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É –¢–ù –í–≠–î"""
        if not code:
            return None

        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–¥–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        clean_code = ''.join(filter(str.isdigit, code))

        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if clean_code in self.codes_index:
            return self.codes_index[clean_code]

        # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞—á–∞–ª—É –∫–æ–¥–∞ (–¥–ª—è –Ω–µ–ø–æ–ª–Ω—ã—Ö –∫–æ–¥–æ–≤)
        for indexed_code, data in self.codes_index.items():
            if indexed_code.startswith(clean_code):
                return data

        return None

    def search_by_name(self, query: str, limit: int = 10) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–æ–≤–∞—Ä–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not query or len(query) < 2:
            return []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = f"name_{query.lower()}_{limit}"
        if cache_key in self._cache:
            return self._cache[cache_key]

        query_lower = query.lower()
        results = []
        seen_codes = set()

        # –ü–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ª–æ–≤–∞–º
        words = query_lower.split()
        for word in words:
            if word in self.name_index:
                for code_data in self.name_index[word]:
                    code = code_data.get("code", "")
                    if code not in seen_codes:
                        results.append(code_data)
                        seen_codes.add(code)
                        if len(results) >= limit:
                            break
            if len(results) >= limit:
                break

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É, –∏—â–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
        if not results:
            for code_data in self.database.get("codes", []):
                name = code_data.get("name", "").lower()
                description = code_data.get("description", "").lower()

                if query_lower in name or query_lower in description:
                    code = code_data.get("code", "")
                    if code not in seen_codes:
                        results.append(code_data)
                        seen_codes.add(code)
                        if len(results) >= limit:
                            break

        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self._cache[cache_key] = results[:limit]
        return results[:limit]

    def get_group_info(self, group_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥—Ä—É–ø–ø–µ"""
        for group in self.database.get("groups", []):
            if group.get("id") == group_id:
                return group
        return None

    def get_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        codes = self.database.get("codes", [])
        groups = self.database.get("groups", [])

        return {
            "total_codes": len(codes),
            "total_groups": len(groups),
            "index_size": len(self.codes_index),
            "cache_size": len(self._cache),
            "version": self.database.get("metadata", {}).get("version", "unknown")
        }

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –ø–æ–∏—Å–∫–∞"""
        self._cache.clear()
        logger.info("üóëÔ∏è –ö—ç—à –æ—á–∏—â–µ–Ω")